{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN0Rab6LivlGNqFmSZZdmD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaheshbabuAmuda/NLP/blob/main/Assignment_1(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TF IDF matrix of given sentences"
      ],
      "metadata": {
        "id": "KH8Y0gYsZe6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "GYLR3UtmZv19"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"\"\"Text Simplification is the task of reducing the complexity of the vocabulary and \n",
        "sentence structure of text while retaining its original meaning, with the goal of \n",
        "improving readability and understanding.\"\"\"\n",
        "\n",
        "text2 = \"\"\"\n",
        "Sentiment Analysis is the process of determining whether a piece of writing is \n",
        "positive, negative or neutral. A sentiment analysis system for text analysis \n",
        "combines natural language processing (NLP) and machine learning techniques to \n",
        "assign weighted sentiment scores to the entities, topics, themes and categories \n",
        "within a sentence or phrase.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "LC5hEO_NZ4y2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string = [text1, text2]"
      ],
      "metadata": {
        "id": "LDnbcAOlaiwv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "MgwCEwOdatYt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = tfidf.fit_transform(string)"
      ],
      "metadata": {
        "id": "xv41wykPa0YQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nidf values:')\n",
        "for ele1, ele2 in zip(tfidf.get_feature_names(), tfidf.idf_):\n",
        "    print(ele1, ':', ele2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1dBrDvqbBBu",
        "outputId": "a787e33c-4bfb-4cf8-e7db-679055d2722e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "idf values:\n",
            "analysis : 1.4054651081081644\n",
            "and : 1.0\n",
            "assign : 1.4054651081081644\n",
            "categories : 1.4054651081081644\n",
            "combines : 1.4054651081081644\n",
            "complexity : 1.4054651081081644\n",
            "determining : 1.4054651081081644\n",
            "entities : 1.4054651081081644\n",
            "for : 1.4054651081081644\n",
            "goal : 1.4054651081081644\n",
            "improving : 1.4054651081081644\n",
            "is : 1.0\n",
            "its : 1.4054651081081644\n",
            "language : 1.4054651081081644\n",
            "learning : 1.4054651081081644\n",
            "machine : 1.4054651081081644\n",
            "meaning : 1.4054651081081644\n",
            "natural : 1.4054651081081644\n",
            "negative : 1.4054651081081644\n",
            "neutral : 1.4054651081081644\n",
            "nlp : 1.4054651081081644\n",
            "of : 1.0\n",
            "or : 1.4054651081081644\n",
            "original : 1.4054651081081644\n",
            "phrase : 1.4054651081081644\n",
            "piece : 1.4054651081081644\n",
            "positive : 1.4054651081081644\n",
            "process : 1.4054651081081644\n",
            "processing : 1.4054651081081644\n",
            "readability : 1.4054651081081644\n",
            "reducing : 1.4054651081081644\n",
            "retaining : 1.4054651081081644\n",
            "scores : 1.4054651081081644\n",
            "sentence : 1.0\n",
            "sentiment : 1.4054651081081644\n",
            "simplification : 1.4054651081081644\n",
            "structure : 1.4054651081081644\n",
            "system : 1.4054651081081644\n",
            "task : 1.4054651081081644\n",
            "techniques : 1.4054651081081644\n",
            "text : 1.0\n",
            "the : 1.0\n",
            "themes : 1.4054651081081644\n",
            "to : 1.4054651081081644\n",
            "topics : 1.4054651081081644\n",
            "understanding : 1.4054651081081644\n",
            "vocabulary : 1.4054651081081644\n",
            "weighted : 1.4054651081081644\n",
            "whether : 1.4054651081081644\n",
            "while : 1.4054651081081644\n",
            "with : 1.4054651081081644\n",
            "within : 1.4054651081081644\n",
            "writing : 1.4054651081081644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nWord indexes:')\n",
        "print(tfidf.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCqnyc6CbFgD",
        "outputId": "3d20e99a-6d67-4339-8f5c-e34920790214"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word indexes:\n",
            "{'text': 40, 'simplification': 35, 'is': 11, 'the': 41, 'task': 38, 'of': 21, 'reducing': 30, 'complexity': 5, 'vocabulary': 46, 'and': 1, 'sentence': 33, 'structure': 36, 'while': 49, 'retaining': 31, 'its': 12, 'original': 23, 'meaning': 16, 'with': 50, 'goal': 9, 'improving': 10, 'readability': 29, 'understanding': 45, 'sentiment': 34, 'analysis': 0, 'process': 27, 'determining': 6, 'whether': 48, 'piece': 25, 'writing': 52, 'positive': 26, 'negative': 18, 'or': 22, 'neutral': 19, 'system': 37, 'for': 8, 'combines': 4, 'natural': 17, 'language': 13, 'processing': 28, 'nlp': 20, 'machine': 15, 'learning': 14, 'techniques': 39, 'to': 43, 'assign': 2, 'weighted': 47, 'scores': 32, 'entities': 7, 'topics': 44, 'themes': 42, 'categories': 3, 'within': 51, 'phrase': 24}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\ntf-idf value:')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKm3A3XZbLUP",
        "outputId": "639fafb0-5d80-4aa2-813e-5d75f262d786"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "tf-idf value:\n",
            "  (0, 45)\t0.16381945672272036\n",
            "  (0, 29)\t0.16381945672272036\n",
            "  (0, 10)\t0.16381945672272036\n",
            "  (0, 9)\t0.16381945672272036\n",
            "  (0, 50)\t0.16381945672272036\n",
            "  (0, 16)\t0.16381945672272036\n",
            "  (0, 23)\t0.16381945672272036\n",
            "  (0, 12)\t0.16381945672272036\n",
            "  (0, 31)\t0.16381945672272036\n",
            "  (0, 49)\t0.16381945672272036\n",
            "  (0, 36)\t0.16381945672272036\n",
            "  (0, 33)\t0.11655889269512398\n",
            "  (0, 1)\t0.23311778539024797\n",
            "  (0, 46)\t0.16381945672272036\n",
            "  (0, 5)\t0.16381945672272036\n",
            "  (0, 30)\t0.16381945672272036\n",
            "  (0, 21)\t0.46623557078049593\n",
            "  (0, 38)\t0.16381945672272036\n",
            "  (0, 41)\t0.46623557078049593\n",
            "  (0, 11)\t0.11655889269512398\n",
            "  (0, 35)\t0.16381945672272036\n",
            "  (0, 40)\t0.23311778539024797\n",
            "  (1, 24)\t0.12688517254111364\n",
            "  (1, 51)\t0.12688517254111364\n",
            "  (1, 3)\t0.12688517254111364\n",
            "  :\t:\n",
            "  (1, 15)\t0.12688517254111364\n",
            "  (1, 20)\t0.12688517254111364\n",
            "  (1, 28)\t0.12688517254111364\n",
            "  (1, 13)\t0.12688517254111364\n",
            "  (1, 17)\t0.12688517254111364\n",
            "  (1, 4)\t0.12688517254111364\n",
            "  (1, 8)\t0.12688517254111364\n",
            "  (1, 37)\t0.12688517254111364\n",
            "  (1, 19)\t0.12688517254111364\n",
            "  (1, 22)\t0.2537703450822273\n",
            "  (1, 18)\t0.12688517254111364\n",
            "  (1, 26)\t0.12688517254111364\n",
            "  (1, 52)\t0.12688517254111364\n",
            "  (1, 25)\t0.12688517254111364\n",
            "  (1, 48)\t0.12688517254111364\n",
            "  (1, 6)\t0.12688517254111364\n",
            "  (1, 27)\t0.12688517254111364\n",
            "  (1, 0)\t0.3806555176233409\n",
            "  (1, 34)\t0.3806555176233409\n",
            "  (1, 33)\t0.09027984530466805\n",
            "  (1, 1)\t0.1805596906093361\n",
            "  (1, 21)\t0.1805596906093361\n",
            "  (1, 41)\t0.1805596906093361\n",
            "  (1, 11)\t0.1805596906093361\n",
            "  (1, 40)\t0.09027984530466805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\ntf-idf values in matrix form:')\n",
        "print(result.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcppH2u8bSGp",
        "outputId": "0a8ed117-8af0-4488-ebb9-26bc7e0615e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "tf-idf values in matrix form:\n",
            "[[0.         0.23311779 0.         0.         0.         0.16381946\n",
            "  0.         0.         0.         0.16381946 0.16381946 0.11655889\n",
            "  0.16381946 0.         0.         0.         0.16381946 0.\n",
            "  0.         0.         0.         0.46623557 0.         0.16381946\n",
            "  0.         0.         0.         0.         0.         0.16381946\n",
            "  0.16381946 0.16381946 0.         0.11655889 0.         0.16381946\n",
            "  0.16381946 0.         0.16381946 0.         0.23311779 0.46623557\n",
            "  0.         0.         0.         0.16381946 0.16381946 0.\n",
            "  0.         0.16381946 0.16381946 0.         0.        ]\n",
            " [0.38065552 0.18055969 0.12688517 0.12688517 0.12688517 0.\n",
            "  0.12688517 0.12688517 0.12688517 0.         0.         0.18055969\n",
            "  0.         0.12688517 0.12688517 0.12688517 0.         0.12688517\n",
            "  0.12688517 0.12688517 0.12688517 0.18055969 0.25377035 0.\n",
            "  0.12688517 0.12688517 0.12688517 0.12688517 0.12688517 0.\n",
            "  0.         0.         0.12688517 0.09027985 0.38065552 0.\n",
            "  0.         0.12688517 0.         0.12688517 0.09027985 0.18055969\n",
            "  0.12688517 0.25377035 0.12688517 0.         0.         0.12688517\n",
            "  0.12688517 0.         0.         0.12688517 0.12688517]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D_X1xNKjbptR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_80IrKv8buHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "80KolXQKbtvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The cosine similarities between given sentences:"
      ],
      "metadata": {
        "id": "WFYYNgkPWlWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "WORD = re.compile(r\"\\w+\")\n",
        "\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
        "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "\n",
        "def text_to_vector(text):\n",
        "    words = WORD.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "\n",
        "text1 = \"\"\"Text Simplification is the task of reducing the complexity of the vocabulary and \n",
        "sentence structure of text while retaining its original meaning, with the goal of \n",
        "improving readability and understanding.\"\"\"\n",
        "\n",
        "text2 = \"\"\"\n",
        "Sentiment Analysis is the process of determining whether a piece of writing is \n",
        "positive, negative or neutral. A sentiment analysis system for text analysis \n",
        "combines natural language processing (NLP) and machine learning techniques to \n",
        "assign weighted sentiment scores to the entities, topics, themes and categories \n",
        "within a sentence or phrase.\n",
        "\"\"\"\n",
        "vector1 = text_to_vector(text1)\n",
        "vector2 = text_to_vector(text2)\n",
        "\n",
        "cosine = get_cosine(vector1, vector2)\n",
        "\n",
        "print(\"Cosine:\", cosine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd6XyjfoVtQp",
        "outputId": "1f0b1846-8295-413d-9a7d-c3be6d4636f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine: 0.38892223413129867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrMQNiJ-bxk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}